# coding: utf-8

"""
    MongoDB Atlas Administration API

    The MongoDB Atlas Administration API allows developers to manage all components in MongoDB Atlas. To learn more, review the [Administration API overview](https://www.mongodb.com/docs/atlas/api/atlas-admin-api/). This OpenAPI specification covers all of the collections with the exception of Alerts, Alert Configurations, and Events. Refer to the [legacy documentation](https://www.mongodb.com/docs/atlas/reference/api-resources/) for the specifications of these resources.  # noqa: E501

    The version of the OpenAPI document: 2.0
    Generated by: https://openapi-generator.tech
"""


from __future__ import annotations
from inspect import getfullargspec
import json
import pprint
import re  # noqa: F401

from typing import Optional
from pydantic import BaseModel, Field, StrictStr, ValidationError, validator
from atlas.models.token_filterascii_folding import TokenFilterasciiFolding
from atlas.models.token_filterdaitch_mokotoff_soundex import TokenFilterdaitchMokotoffSoundex
from atlas.models.token_filteredge_gram import TokenFilteredgeGram
from atlas.models.token_filtericu_folding import TokenFiltericuFolding
from atlas.models.token_filtericu_normalizer import TokenFiltericuNormalizer
from atlas.models.token_filterlength import TokenFilterlength
from atlas.models.token_filterlowercase import TokenFilterlowercase
from atlas.models.token_filtern_gram import TokenFilternGram
from atlas.models.token_filterregex import TokenFilterregex
from atlas.models.token_filterreverse import TokenFilterreverse
from atlas.models.token_filtershingle import TokenFiltershingle
from atlas.models.token_filtersnowball_stemming import TokenFiltersnowballStemming
from atlas.models.token_filterstopword import TokenFilterstopword
from atlas.models.token_filtertrim import TokenFiltertrim
from typing import Any, List
from pydantic import StrictStr, Field

APIATLASFTSANALYZERSVIEWMANUALTOKENFILTERSINNER_ANY_OF_SCHEMAS = ["TokenFilterasciiFolding", "TokenFilterdaitchMokotoffSoundex", "TokenFilteredgeGram", "TokenFiltericuFolding", "TokenFiltericuNormalizer", "TokenFilterlength", "TokenFilterlowercase", "TokenFilternGram", "TokenFilterregex", "TokenFilterreverse", "TokenFiltershingle", "TokenFiltersnowballStemming", "TokenFilterstopword", "TokenFiltertrim"]

class ApiAtlasFTSAnalyzersViewManualTokenFiltersInner(BaseModel):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """
    # data type: TokenFilterasciiFolding
    anyof_schema_1_validator: Optional[TokenFilterasciiFolding] = None
    # data type: TokenFilterdaitchMokotoffSoundex
    anyof_schema_2_validator: Optional[TokenFilterdaitchMokotoffSoundex] = None
    # data type: TokenFilteredgeGram
    anyof_schema_3_validator: Optional[TokenFilteredgeGram] = None
    # data type: TokenFiltericuFolding
    anyof_schema_4_validator: Optional[TokenFiltericuFolding] = None
    # data type: TokenFiltericuNormalizer
    anyof_schema_5_validator: Optional[TokenFiltericuNormalizer] = None
    # data type: TokenFilterlength
    anyof_schema_6_validator: Optional[TokenFilterlength] = None
    # data type: TokenFilterlowercase
    anyof_schema_7_validator: Optional[TokenFilterlowercase] = None
    # data type: TokenFilternGram
    anyof_schema_8_validator: Optional[TokenFilternGram] = None
    # data type: TokenFilterregex
    anyof_schema_9_validator: Optional[TokenFilterregex] = None
    # data type: TokenFilterreverse
    anyof_schema_10_validator: Optional[TokenFilterreverse] = None
    # data type: TokenFiltershingle
    anyof_schema_11_validator: Optional[TokenFiltershingle] = None
    # data type: TokenFiltersnowballStemming
    anyof_schema_12_validator: Optional[TokenFiltersnowballStemming] = None
    # data type: TokenFilterstopword
    anyof_schema_13_validator: Optional[TokenFilterstopword] = None
    # data type: TokenFiltertrim
    anyof_schema_14_validator: Optional[TokenFiltertrim] = None
    actual_instance: Any
    any_of_schemas: List[str] = Field(APIATLASFTSANALYZERSVIEWMANUALTOKENFILTERSINNER_ANY_OF_SCHEMAS, const=True)

    class Config:
        validate_assignment = True

    @validator('actual_instance')
    def actual_instance_must_validate_anyof(cls, v):
        instance = cls()
        error_messages = []
        # validate data type: TokenFilterasciiFolding
        if type(v) is not TokenFilterasciiFolding:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterasciiFolding`")
        else:
            return v

        # validate data type: TokenFilterdaitchMokotoffSoundex
        if type(v) is not TokenFilterdaitchMokotoffSoundex:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterdaitchMokotoffSoundex`")
        else:
            return v

        # validate data type: TokenFilteredgeGram
        if type(v) is not TokenFilteredgeGram:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilteredgeGram`")
        else:
            return v

        # validate data type: TokenFiltericuFolding
        if type(v) is not TokenFiltericuFolding:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFiltericuFolding`")
        else:
            return v

        # validate data type: TokenFiltericuNormalizer
        if type(v) is not TokenFiltericuNormalizer:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFiltericuNormalizer`")
        else:
            return v

        # validate data type: TokenFilterlength
        if type(v) is not TokenFilterlength:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterlength`")
        else:
            return v

        # validate data type: TokenFilterlowercase
        if type(v) is not TokenFilterlowercase:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterlowercase`")
        else:
            return v

        # validate data type: TokenFilternGram
        if type(v) is not TokenFilternGram:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilternGram`")
        else:
            return v

        # validate data type: TokenFilterregex
        if type(v) is not TokenFilterregex:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterregex`")
        else:
            return v

        # validate data type: TokenFilterreverse
        if type(v) is not TokenFilterreverse:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterreverse`")
        else:
            return v

        # validate data type: TokenFiltershingle
        if type(v) is not TokenFiltershingle:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFiltershingle`")
        else:
            return v

        # validate data type: TokenFiltersnowballStemming
        if type(v) is not TokenFiltersnowballStemming:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFiltersnowballStemming`")
        else:
            return v

        # validate data type: TokenFilterstopword
        if type(v) is not TokenFilterstopword:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFilterstopword`")
        else:
            return v

        # validate data type: TokenFiltertrim
        if type(v) is not TokenFiltertrim:
            error_messages.append(f"Error! Input type `{type(v)}` is not `TokenFiltertrim`")
        else:
            return v

        if error_messages:
            # no match
            raise ValueError("No match found when deserializing the JSON string into ApiAtlasFTSAnalyzersViewManualTokenFiltersInner with anyOf schemas: TokenFilterasciiFolding, TokenFilterdaitchMokotoffSoundex, TokenFilteredgeGram, TokenFiltericuFolding, TokenFiltericuNormalizer, TokenFilterlength, TokenFilterlowercase, TokenFilternGram, TokenFilterregex, TokenFilterreverse, TokenFiltershingle, TokenFiltersnowballStemming, TokenFilterstopword, TokenFiltertrim. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_json(cls, json_str: str) -> ApiAtlasFTSAnalyzersViewManualTokenFiltersInner:
        """Returns the object represented by the json string"""
        instance = cls()
        error_messages = []
        # anyof_schema_1_validator: Optional[TokenFilterasciiFolding] = None
        try:
            instance.actual_instance = TokenFilterasciiFolding.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_2_validator: Optional[TokenFilterdaitchMokotoffSoundex] = None
        try:
            instance.actual_instance = TokenFilterdaitchMokotoffSoundex.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_3_validator: Optional[TokenFilteredgeGram] = None
        try:
            instance.actual_instance = TokenFilteredgeGram.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_4_validator: Optional[TokenFiltericuFolding] = None
        try:
            instance.actual_instance = TokenFiltericuFolding.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_5_validator: Optional[TokenFiltericuNormalizer] = None
        try:
            instance.actual_instance = TokenFiltericuNormalizer.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_6_validator: Optional[TokenFilterlength] = None
        try:
            instance.actual_instance = TokenFilterlength.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_7_validator: Optional[TokenFilterlowercase] = None
        try:
            instance.actual_instance = TokenFilterlowercase.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_8_validator: Optional[TokenFilternGram] = None
        try:
            instance.actual_instance = TokenFilternGram.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_9_validator: Optional[TokenFilterregex] = None
        try:
            instance.actual_instance = TokenFilterregex.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_10_validator: Optional[TokenFilterreverse] = None
        try:
            instance.actual_instance = TokenFilterreverse.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_11_validator: Optional[TokenFiltershingle] = None
        try:
            instance.actual_instance = TokenFiltershingle.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_12_validator: Optional[TokenFiltersnowballStemming] = None
        try:
            instance.actual_instance = TokenFiltersnowballStemming.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_13_validator: Optional[TokenFilterstopword] = None
        try:
            instance.actual_instance = TokenFilterstopword.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))
        # anyof_schema_14_validator: Optional[TokenFiltertrim] = None
        try:
            instance.actual_instance = TokenFiltertrim.from_json(json_str)
            return instance
        except ValidationError as e:
             error_messages.append(str(e))

        if error_messages:
            # no match
            raise ValueError("No match found when deserializing the JSON string into ApiAtlasFTSAnalyzersViewManualTokenFiltersInner with anyOf schemas: TokenFilterasciiFolding, TokenFilterdaitchMokotoffSoundex, TokenFilteredgeGram, TokenFiltericuFolding, TokenFiltericuNormalizer, TokenFilterlength, TokenFilterlowercase, TokenFilternGram, TokenFilterregex, TokenFilterreverse, TokenFiltershingle, TokenFiltersnowballStemming, TokenFilterstopword, TokenFiltertrim. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is not None:
            return self.actual_instance.to_json()
        else:
            return "null"

    def to_dict(self) -> dict:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is not None:
            return self.actual_instance.to_dict()
        else:
            return dict()

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.dict())

