# coding: utf-8

"""
    MongoDB Atlas Administration API

    The MongoDB Atlas Administration API allows developers to manage all components in MongoDB Atlas. To learn more, review the [Administration API overview](https://www.mongodb.com/docs/atlas/api/atlas-admin-api/). This OpenAPI specification covers all of the collections with the exception of Alerts, Alert Configurations, and Events. Refer to the [legacy documentation](https://www.mongodb.com/docs/atlas/reference/api-resources/) for the specifications of these resources.  # noqa: E501

    The version of the OpenAPI document: 2.0
    Generated by: https://openapi-generator.tech
"""


from __future__ import annotations
from inspect import getfullargspec
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import List, Optional
from pydantic import BaseModel, Field, StrictStr, constr, validator
from atlas.models.api_export_status_view import ApiExportStatusView
from atlas.models.disk_backup_base_restore_member import DiskBackupBaseRestoreMember
from atlas.models.label import Label
from atlas.models.link import Link

class DiskBackupExportJob(BaseModel):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """
    components: Optional[List[DiskBackupBaseRestoreMember]] = Field(None, description="Information on the export job for each replica set in the sharded cluster.")
    created_at: Optional[datetime] = Field(None, alias="createdAt", description="Date and time when someone created this export job. MongoDB Cloud represents this timestamp in ISO 8601 format in UTC.")
    custom_data: Optional[List[Label]] = Field(None, alias="customData", description="Collection of key-value pairs that represent custom data for the metadata file that MongoDB Cloud uploads to the bucket when the export job finishes.")
    delivery_url: Optional[List[StrictStr]] = Field(None, alias="deliveryUrl", description="One or more Uniform Resource Locators (URLs) that point to the compressed snapshot files for manual download. MongoDB Cloud returns this parameter when `\"deliveryType\" : \"download\"`.")
    export_bucket_id: constr(strict=True, max_length=24, min_length=24) = Field(..., alias="exportBucketId", description="Unique 24-hexadecimal character string that identifies the AWS bucket to which MongoDB Cloud exports the Cloud Backup snapshot.")
    export_status: Optional[ApiExportStatusView] = Field(None, alias="exportStatus")
    finished_at: Optional[datetime] = Field(None, alias="finishedAt", description="Date and time when this export job completed. MongoDB Cloud represents this timestamp in ISO 8601 format in UTC.")
    id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, description="Unique 24-hexadecimal character string that identifies the restore job.")
    links: Optional[List[Link]] = Field(None, description="List of one or more Uniform Resource Locators (URLs) that point to API sub-resources, related API resources, or both. RFC 5988 outlines these relationships.")
    prefix: Optional[constr(strict=True)] = Field(None, description="Full path on the cloud provider bucket to the folder where the snapshot is exported.")
    snapshot_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="snapshotId", description="Unique 24-hexadecimal character string that identifies the snapshot.")
    state: Optional[StrictStr] = Field(None, description="State of the export job.")
    __properties = ["components", "createdAt", "customData", "deliveryUrl", "exportBucketId", "exportStatus", "finishedAt", "id", "links", "prefix", "snapshotId", "state"]

    @validator('export_bucket_id')
    def export_bucket_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('id')
    def id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('prefix')
    def prefix_validate_regular_expression(cls, v):
        if not re.match(r"exported_snapshots/\{ORG-NAME\}/\{PROJECT-NAME\}/\{CLUSTER-NAME\}/\{SNAPSHOT-INITIATION-DATE\}", v):
            raise ValueError(r"must validate the regular expression /exported_snapshots/\{ORG-NAME\}/\{PROJECT-NAME\}/\{CLUSTER-NAME\}/\{SNAPSHOT-INITIATION-DATE\}/\{TIMESTAMP\}")
        return v

    @validator('snapshot_id')
    def snapshot_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('state')
    def state_validate_enum(cls, v):
        if v is None:
            return v

        if v not in ('Cancelled', 'Failed', 'InProgress', 'Queued', 'Successful'):
            raise ValueError("must validate the enum values ('Cancelled', 'Failed', 'InProgress', 'Queued', 'Successful')")
        return v

    class Config:
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> DiskBackupExportJob:
        """Create an instance of DiskBackupExportJob from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True,
                          exclude={
                            "components",
                            "created_at",
                            "delivery_url",
                            "export_bucket_id",
                            "finished_at",
                            "id",
                            "links",
                            "prefix",
                            "state",
                          },
                          exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of each item in components (list)
        _items = []
        if self.components:
            for _item in self.components:
                if _item:
                    _items.append(_item.to_dict())
            _dict['components'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in custom_data (list)
        _items = []
        if self.custom_data:
            for _item in self.custom_data:
                if _item:
                    _items.append(_item.to_dict())
            _dict['customData'] = _items
        # override the default output from pydantic by calling `to_dict()` of export_status
        if self.export_status:
            _dict['exportStatus'] = self.export_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in links (list)
        _items = []
        if self.links:
            for _item in self.links:
                if _item:
                    _items.append(_item.to_dict())
            _dict['links'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> DiskBackupExportJob:
        """Create an instance of DiskBackupExportJob from a dict"""
        if obj is None:
            return None

        if type(obj) is not dict:
            return DiskBackupExportJob.parse_obj(obj)

        _obj = DiskBackupExportJob.parse_obj({
            "components": [DiskBackupBaseRestoreMember.from_dict(_item) for _item in obj.get("components")] if obj.get("components") is not None else None,
            "created_at": obj.get("createdAt"),
            "custom_data": [Label.from_dict(_item) for _item in obj.get("customData")] if obj.get("customData") is not None else None,
            "delivery_url": obj.get("deliveryUrl"),
            "export_bucket_id": obj.get("exportBucketId"),
            "export_status": ApiExportStatusView.from_dict(obj.get("exportStatus")) if obj.get("exportStatus") is not None else None,
            "finished_at": obj.get("finishedAt"),
            "id": obj.get("id"),
            "links": [Link.from_dict(_item) for _item in obj.get("links")] if obj.get("links") is not None else None,
            "prefix": obj.get("prefix"),
            "snapshot_id": obj.get("snapshotId"),
            "state": obj.get("state")
        })
        return _obj

