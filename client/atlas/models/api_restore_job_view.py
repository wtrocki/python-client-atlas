# coding: utf-8

"""
    MongoDB Atlas Administration API

    The MongoDB Atlas Administration API allows developers to manage all components in MongoDB Atlas. To learn more, review the [Administration API overview](https://www.mongodb.com/docs/atlas/api/atlas-admin-api/). This OpenAPI specification covers all of the collections with the exception of Alerts, Alert Configurations, and Events. Refer to the [legacy documentation](https://www.mongodb.com/docs/atlas/reference/api-resources/) for the specifications of these resources.  # noqa: E501

    The version of the OpenAPI document: 2.0
    Generated by: https://openapi-generator.tech
"""


from __future__ import annotations
from inspect import getfullargspec
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import List, Optional
from pydantic import BaseModel, Field, StrictBool, StrictStr, conint, constr, validator
from atlas.models.api_bson_timestamp_view import ApiBSONTimestampView
from atlas.models.api_restore_job_delivery_view import ApiRestoreJobDeliveryView
from atlas.models.api_restore_job_file_hash_view import ApiRestoreJobFileHashView
from atlas.models.link import Link

class ApiRestoreJobView(BaseModel):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """
    batch_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="batchId", description="Unique 24-hexadecimal digit string that identifies the batch to which this restore job belongs. This parameter exists only for a sharded cluster restore.")
    checkpoint_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="checkpointId", description="Unique 24-hexadecimal digit string that identifies the sharded cluster checkpoint. The checkpoint represents the point in time back to which you want to restore you data. This parameter applies when `\"delivery.methodName\" : \"AUTOMATED_RESTORE\"`. Use this parameter with sharded clusters only.  - If you set **checkpointId**, you can't set **oplogInc**, **oplogTs**, **snapshotId**, or **pointInTimeUTCMillis**. - If you provide this parameter, this endpoint restores all data up to this checkpoint to the database you specify in the **delivery** object.")
    cluster_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="clusterId", description="Unique 24-hexadecimal digit string that identifies the cluster with the snapshot you want to return. This parameter returns for restore clusters.")
    cluster_name: Optional[constr(strict=True, max_length=64, min_length=1)] = Field(None, alias="clusterName", description="Human-readable label that identifies the cluster containing the snapshots you want to retrieve.")
    created: Optional[datetime] = Field(None, description="Date and time when someone requested this restore job. This parameter expresses its value in the ISO 8601 timestamp format in UTC.")
    delivery: ApiRestoreJobDeliveryView = ...
    encryption_enabled: Optional[StrictBool] = Field(None, alias="encryptionEnabled", description="Flag that indicates whether someone encrypted the data in the restored snapshot.")
    group_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="groupId", description="Unique 24-hexadecimal digit string that identifies the project that owns the snapshots.")
    hashes: Optional[List[ApiRestoreJobFileHashView]] = Field(None, description="List that contains documents mapping each restore file to a hashed checksum. This parameter applies after you download the corresponding **delivery.url**. If `\"methodName\" : \"HTTP\"`, this list contains one object that represents the hash of the **.tar.gz** file.")
    id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, description="Unique 24-hexadecimal digit string that identifies the restore job.")
    links: Optional[List[Link]] = Field(None, description="List of one or more Uniform Resource Locators (URLs) that point to API sub-resources, related API resources, or both. RFC 5988 outlines these relationships.")
    master_key_uuid: Optional[StrictStr] = Field(None, alias="masterKeyUUID", description="Universally Unique Identifier (UUID) that identifies the Key Management Interoperability (KMIP) master key used to encrypt the snapshot data. This parameter applies only when `\"encryptionEnabled\" : \"true\"`.")
    oplog_inc: Optional[conint(strict=True, ge=1)] = Field(None, alias="oplogInc", description="Thirty-two-bit incrementing ordinal that represents operations within a given second. When paired with **oplogTs**, this represents the point in time to which MongoDB Cloud restores your data. This parameter applies when `\"delivery.methodName\" : \"AUTOMATED_RESTORE\"`.  - If you set **oplogInc**, you must set **oplogTs**, and can't set **checkpointId**, **snapshotId**, or **pointInTimeUTCMillis**. - If you provide this parameter, this endpoint restores all data up to and including this Oplog timestamp to the database you specified in the **delivery** object.")
    oplog_ts: Optional[constr(strict=True)] = Field(None, alias="oplogTs", description="Date and time from which you want to restore this snapshot. This parameter expresses its value in ISO 8601 format in UTC. This represents the first part of an Oplog timestamp. When paired with **oplogInc**, they represent the last database operation to which you want to restore your data. This parameter applies when `\"delivery.methodName\" : \"AUTOMATED_RESTORE\"`. Run a query against **local.oplog.rs** on your replica set to find the desired timestamp.  - If you set **oplogTs**, you must set **oplogInc**, and you can't set **checkpointId**, **snapshotId**, or **pointInTimeUTCMillis**. - If you provide this parameter, this endpoint restores all data up to and including this Oplog timestamp to the database you specified in the **delivery** object.")
    point_in_time_utc_millis: Optional[conint(strict=True, ge=1199145600000)] = Field(None, alias="pointInTimeUTCMillis", description="Timestamp from which you want to restore this snapshot. This parameter expresses its value in the number of milliseconds elapsed since the [UNIX epoch](https://en.wikipedia.org/wiki/Unix_time). This timestamp must fall within the last 24 hours of the current time. This parameter applies when `\"delivery.methodName\" : \"AUTOMATED_RESTORE\"`.  - If you provide this parameter, this endpoint restores all data up to this point in time to the database you specified in the **delivery** object. - If you set **pointInTimeUTCMillis**, you can't set **oplogInc**, **oplogTs**, **snapshotId**, or **checkpointId**.")
    snapshot_id: Optional[constr(strict=True, max_length=24, min_length=24)] = Field(None, alias="snapshotId", description="Unique 24-hexadecimal digit string that identifies the snapshot to restore. If you set **snapshotId**, you can't set **oplogInc**, **oplogTs**, **pointInTimeUTCMillis**, or **checkpointId**.")
    status_name: Optional[StrictStr] = Field(None, alias="statusName", description="Human-readable label that identifies the status of the downloadable file at the time of the request.")
    timestamp: Optional[ApiBSONTimestampView] = None
    __properties = ["batchId", "checkpointId", "clusterId", "clusterName", "created", "delivery", "encryptionEnabled", "groupId", "hashes", "id", "links", "masterKeyUUID", "oplogInc", "oplogTs", "pointInTimeUTCMillis", "snapshotId", "statusName", "timestamp"]

    @validator('batch_id')
    def batch_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('checkpoint_id')
    def checkpoint_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('cluster_id')
    def cluster_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('cluster_name')
    def cluster_name_validate_regular_expression(cls, v):
        if not re.match(r"^([a-zA-Z0-9]([a-zA-Z0-9-]){0,21}(?<!-)([\w]{0,42}))$", v):
            raise ValueError(r"must validate the regular expression /^([a-zA-Z0-9]([a-zA-Z0-9-]){0,21}(?<!-)([\w]{0,42}))$/")
        return v

    @validator('group_id')
    def group_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('id')
    def id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('oplog_ts')
    def oplog_ts_validate_regular_expression(cls, v):
        if not re.match(r"^(?:[1-9]\\d{3}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1\\d|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[1-9]\\d(?:0[48]|[2468][048]|[13579][26])|(?:[2468][048]|[13579][26])00)-02-29)T(?:[01]\\d|2[0-3]):[0-5]\\d:[0-5]\\d(?:\\.\\d{1,9})?(?:Z|[+-][01]\\d:[0-5]\\d)$", v):
            raise ValueError(r"must validate the regular expression /^(?:[1-9]\\d{3}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1\\d|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[1-9]\\d(?:0[48]|[2468][048]|[13579][26])|(?:[2468][048]|[13579][26])00)-02-29)T(?:[01]\\d|2[0-3]):[0-5]\\d:[0-5]\\d(?:\\.\\d{1,9})?(?:Z|[+-][01]\\d:[0-5]\\d)$/")
        return v

    @validator('snapshot_id')
    def snapshot_id_validate_regular_expression(cls, v):
        if not re.match(r"^([a-f0-9]{24})$", v):
            raise ValueError(r"must validate the regular expression /^([a-f0-9]{24})$/")
        return v

    @validator('status_name')
    def status_name_validate_enum(cls, v):
        if v is None:
            return v

        if v not in ('IN_PROGRESS', 'BROKEN', 'KILLED', 'FINISHED'):
            raise ValueError("must validate the enum values ('IN_PROGRESS', 'BROKEN', 'KILLED', 'FINISHED')")
        return v

    class Config:
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> ApiRestoreJobView:
        """Create an instance of ApiRestoreJobView from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True,
                          exclude={
                            "batch_id",
                            "cluster_id",
                            "cluster_name",
                            "created",
                            "encryption_enabled",
                            "group_id",
                            "hashes",
                            "id",
                            "links",
                            "master_key_uuid",
                            "status_name",
                          },
                          exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of delivery
        if self.delivery:
            _dict['delivery'] = self.delivery.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in hashes (list)
        _items = []
        if self.hashes:
            for _item in self.hashes:
                if _item:
                    _items.append(_item.to_dict())
            _dict['hashes'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in links (list)
        _items = []
        if self.links:
            for _item in self.links:
                if _item:
                    _items.append(_item.to_dict())
            _dict['links'] = _items
        # override the default output from pydantic by calling `to_dict()` of timestamp
        if self.timestamp:
            _dict['timestamp'] = self.timestamp.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> ApiRestoreJobView:
        """Create an instance of ApiRestoreJobView from a dict"""
        if obj is None:
            return None

        if type(obj) is not dict:
            return ApiRestoreJobView.parse_obj(obj)

        _obj = ApiRestoreJobView.parse_obj({
            "batch_id": obj.get("batchId"),
            "checkpoint_id": obj.get("checkpointId"),
            "cluster_id": obj.get("clusterId"),
            "cluster_name": obj.get("clusterName"),
            "created": obj.get("created"),
            "delivery": ApiRestoreJobDeliveryView.from_dict(obj.get("delivery")) if obj.get("delivery") is not None else None,
            "encryption_enabled": obj.get("encryptionEnabled"),
            "group_id": obj.get("groupId"),
            "hashes": [ApiRestoreJobFileHashView.from_dict(_item) for _item in obj.get("hashes")] if obj.get("hashes") is not None else None,
            "id": obj.get("id"),
            "links": [Link.from_dict(_item) for _item in obj.get("links")] if obj.get("links") is not None else None,
            "master_key_uuid": obj.get("masterKeyUUID"),
            "oplog_inc": obj.get("oplogInc"),
            "oplog_ts": obj.get("oplogTs"),
            "point_in_time_utc_millis": obj.get("pointInTimeUTCMillis"),
            "snapshot_id": obj.get("snapshotId"),
            "status_name": obj.get("statusName"),
            "timestamp": ApiBSONTimestampView.from_dict(obj.get("timestamp")) if obj.get("timestamp") is not None else None
        })
        return _obj

